{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f132519-28db-44cb-8ce0-08c2ded17a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concantenate all bfactor data into csv file\n",
      "Created a subset of all bfactor data to only include from Apo\n",
      "Files ending with '5.0_bfactor_subset.csv' have been successfully transferred to the separate folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harrw10\\AppData\\Local\\Temp\\ipykernel_27628\\311521010.py:91: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_5_bfactor_subset_df = pd.concat(dataframes, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined all bfactor with 5.0 closeres data into single csv\n",
      "Created a bfactor 5.0 clsoeres subset to only include Apo structures\n",
      "Saved Z-score normalized B-factor histograms to /Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_bfactor_histograms_overlay_zscore_normalized\\zscore_normalized_b_factor_histograms.png\n",
      "Z-score normalized B-Factor histograms created successfully!\n",
      "B-factor data analysis complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy import stats\n",
    "import shutil\n",
    "import mplcursors\n",
    "\n",
    "#How to import all B factor values then concantenate all dataframes into a single dataframe from the analysis scripts\n",
    "#Use glob to find all *_B_factors.csv files in the specified directory\n",
    "b_factor_files = glob.glob(os.path.join('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein', '*_B_factors.csv'))\n",
    "\n",
    "#Initialize a list to store the DataFrames\n",
    "b_factor_dfs = []\n",
    "\n",
    "#Loop through each file and read it into a DataFrame\n",
    "for file in b_factor_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # Optionally, add a new column to identify the source file\n",
    "    b_factor_dfs.append(df)\n",
    "\n",
    "#Concatenate all DataFrames into a single DataFrame\n",
    "combined_b_factor_df = pd.concat(b_factor_dfs, ignore_index=True)\n",
    "combined_b_factor_df['chain'] = combined_b_factor_df['chain'].str.replace(r\"[\\[\\]']+\", '', regex=True).str.strip()\n",
    "combined_b_factor_df['resn'] = combined_b_factor_df['resn'].str.replace(r\"[\\[\\]']+\", '', regex=True).str.strip()\n",
    "\n",
    "b_factor_data = combined_b_factor_df\n",
    "b_factor_data.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/b_factor_data.csv')\n",
    "print(\"Concantenate all bfactor data into csv file\")\n",
    "\n",
    "#How to combine aspects of the 'Apo' data into a singular file, this example is for combining B factor and Apo data\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "#Define criteria for apo_res structure\n",
    "def apo_df():\n",
    "    filtered_2_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "#Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    filtered_2_df = filtered_2_df[apo_columns]\n",
    "    return filtered_2_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_b_factor_aligned = combined_b_factor_df[combined_b_factor_df['PDB'] .isin (apo_data['Apo'])]\n",
    "apo_b_factor_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_b_factor_aligned.csv',index=False)\n",
    "print(\"Created a subset of all bfactor data to only include from Apo\")\n",
    "\n",
    "#How to separate the _5.0_bfactor_subset files from the entire data set and transfer them into an individual folder\n",
    "#Define the source and destination directories\n",
    "source_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/full_protein-20241018T143402Z-001/full_protein/'\n",
    "destination_directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_bfactor_subset_files/'\n",
    "\n",
    "#Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_directory, exist_ok=True)\n",
    "\n",
    "#List all files in the source directory\n",
    "file_list = os.listdir(source_directory)\n",
    "\n",
    "#Loop through each file and transfer files ending with qFit_sasa.csv to the destination directory\n",
    "for file in file_list:\n",
    "    if file.endswith('_5.0_bfactor_subset.csv'):\n",
    "        source_file_path = os.path.join(source_directory, file)\n",
    "        destination_file_path = os.path.join(destination_directory, file)\n",
    "        shutil.move(source_file_path, destination_file_path)\n",
    "\n",
    "print(\"Files ending with '5.0_bfactor_subset.csv' have been successfully transferred to the separate folder.\")\n",
    "\n",
    "#How to add the PDB variable to each 5_bfactor_subset file then concantenate all dataframes into a single dataframe from the analysis scripts\n",
    "#Directory containing the .csv files\n",
    "directory = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_bfactor_subset_files'\n",
    "\n",
    "#Initialize an empty list to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "#List all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        #Extract the base name without extension and remove \n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        cleaned_base_name = base_name.replace('_5.0_bfactor_subset', '')\n",
    "     #Read the csv file into a dataframe\n",
    "        _5_bfactor_subset_df = pd.read_csv(os.path.join(directory, filename))\n",
    "        \n",
    "        #Add a new column with the cleaned base name\n",
    "        _5_bfactor_subset_df['Cleaned Base Name'] = cleaned_base_name\n",
    "        \n",
    "        #Append the dataframe to the list\n",
    "        dataframes.append(_5_bfactor_subset_df)\n",
    "#Concatenate all dataframes in the list into a single dataframe\n",
    "combined_5_bfactor_subset_df = pd.concat(dataframes, ignore_index=True)  \n",
    "combined_5_bfactor_subset_df.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt//Stephanie Wankowicz research/5_bfactor_subset_files/combined_5_bfactor_subset_df.csv', index=False)\n",
    "print(\"combined all bfactor with 5.0 closeres data into single csv\")\n",
    "\n",
    "#How to combine aspects of the 'Apo' data and 5_bfactor_subset into a singular file\n",
    "df = pd.read_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/apo_holo_241016.csv')\n",
    "\n",
    "#Define criteria for apo_res structure\n",
    "def apo_df():\n",
    "    filtered_2_df = df[df['Apo'].notna() & (df['Apo'] != '')]\n",
    "#Select only the desired columns\n",
    "    apo_columns = ['Apo']\n",
    "    filtered_2_df = filtered_2_df[apo_columns]\n",
    "    return filtered_2_df\n",
    "apo_data = apo_df()\n",
    "\n",
    "apo_5_bfactor_subset_aligned = combined_5_bfactor_subset_df[combined_5_bfactor_subset_df['Cleaned Base Name'] .isin (apo_data['Apo'])]\n",
    "apo_5_bfactor_subset_aligned.to_csv('/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_bfactor_subset_aligned.csv',index=False)\n",
    "print(\"Created a bfactor 5.0 clsoeres subset to only include Apo structures\") \n",
    "\n",
    "#Create the histograms of the OP data and normalize the data using z-score\n",
    "def plot_zscore_normalized_overlaid_b_factor_histograms(df1, df2, label1, label2, output_dir):\n",
    "    fig, ax = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    #Calculate normalization parameters from df1 only\n",
    "    mean_df1 = df1['b_factor'].mean()\n",
    "    std_df1 = df1['b_factor'].std()\n",
    "    \n",
    "    #Z-score normalize both datasets using df1's parameters\n",
    "    df1_zscore = (df1['b_factor'] - mean_df1) / std_df1\n",
    "    df2_zscore = (df2['b_factor'] - mean_df1) / std_df1\n",
    "    \n",
    "    #Create the histograms with z-scored data\n",
    "    bins = np.linspace(min(df1_zscore.min(), df2_zscore.min()),\n",
    "                      max(df1_zscore.max(), df2_zscore.max()),\n",
    "                      100)\n",
    "    \n",
    "    n1, bins1, patches1 = ax.hist(df1_zscore, bins=bins, \n",
    "                                 alpha=0.5, label=label1, color='blue', density=True)\n",
    "    n2, bins2, patches2 = ax.hist(df2_zscore, bins=bins, \n",
    "                                 alpha=0.5, label=label2, color='red', density=True)\n",
    "    \n",
    "    ax.set_title('Z-Score Normalized B-factor Histograms')\n",
    "    ax.set_xlabel('b_factor (Z-score)')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #Add hover annotations\n",
    "    cursor = mplcursors.cursor(patches1 + patches2, hover=True)\n",
    "    \n",
    "    @cursor.connect(\"add\")\n",
    "    def on_add(sel):\n",
    "        if sel.artist in patches1:\n",
    "            index = patches1.index(sel.artist)\n",
    "            dataset = label1\n",
    "            density = n1[index]\n",
    "        else:\n",
    "            index = patches2.index(sel.artist)\n",
    "            dataset = label2\n",
    "            density = n2[index]\n",
    "        \n",
    "        sel.annotation.set_text(\n",
    "            f'Dataset: {dataset}\\n'\n",
    "            f'Z-score range: {bins[index]:.2f} - {bins[index+1]:.2f}\\n'\n",
    "            f'Density: {density:.4f}'\n",
    "        )\n",
    "    \n",
    "    output_file = os.path.join(output_dir, 'zscore_normalized_b_factor_histograms.png')\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Saved Z-score normalized B-factor histograms to {output_file}\")\n",
    "#Define the file path per dataframe and output directory for histogram\n",
    "def process_datasets(file_path1, file_path2, label1, label2, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    plot_zscore_normalized_overlaid_b_factor_histograms(df1, df2, label1, label2, output_dir)\n",
    "    print(\"Z-score normalized B-Factor histograms created successfully!\")\n",
    "\n",
    "# File paths and settings\n",
    "file_path1 = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_b_factor_aligned.csv'\n",
    "file_path2 = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_5_bfactor_subset_aligned.csv'\n",
    "label1 = 'Apo b-factors'\n",
    "label2 = 'Apo b-factors 5.0 closeres'\n",
    "output_dir = '/Users/harrw10/OneDrive - Vanderbilt/Documents/Vanderbilt/Stephanie Wankowicz research/combined_full_protein_data/apo_bfactor_histograms_overlay_zscore_normalized'\n",
    "\n",
    "# Process the datasets\n",
    "process_datasets(file_path1, file_path2, label1, label2, output_dir)\n",
    "print(\"B-factor data analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1a0bb0-1166-4643-85ad-0866e3904ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
